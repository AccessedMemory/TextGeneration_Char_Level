{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AskReddit_Character_Model.ipynb","provenance":[],"collapsed_sections":["oQZY9HQzAuFm","sHd_cCyOApbf","DiIQbCuQBRQV","RsHFmG18CcSF","RzcQK4YfDitG","9h86zX7vF41X","p2cGsgk2Htve","FuE0ORWBLdJW","RS9qQo5BLKdG"],"authorship_tag":"ABX9TyNay0A2K8b5x9YV1iWb19Ey"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Cam9KBK8_K1P"},"source":["# Generating Ask Reddit Questions Character-by-Character\n","\n","In this notebook, we will take 5000 top, rising, new (as of May 2021) and general (from January 2018) questions submitted to the SubReddit 'askreddit' (*https://www.reddit.com/r/AskReddit/*) and train a Recurrent Neural Network (RNN) to learn the English language and produce it's own questions to be submitted to askreddit!\n","\n","This method was based of the tutorial provided by TensorFlow here: https://www.tensorflow.org/tutorials/text/text_generation.\n","\n","*This notebook will work best with a GPU enabled*."]},{"cell_type":"markdown","metadata":{"id":"oQZY9HQzAuFm"},"source":["# Mount Drive"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DPOYBgrOAxc2","executionInfo":{"status":"ok","timestamp":1620477400397,"user_tz":-60,"elapsed":18225,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"6d620de4-0b0d-4f40-a586-1fe81683bb3e"},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sHd_cCyOApbf"},"source":["# Import Packages"]},{"cell_type":"code","metadata":{"id":"og2hVKPF-9lZ","executionInfo":{"status":"ok","timestamp":1620478118286,"user_tz":-60,"elapsed":566,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils\n","\n","\n","import tensorflow as tf\n","from tensorflow.keras.layers.experimental import preprocessing\n","\n","from nltk.translate.bleu_score import sentence_bleu\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","\n","import warnings\n","warnings.simplefilter('ignore')"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiIQbCuQBRQV"},"source":["# Load Data"]},{"cell_type":"markdown","metadata":{"id":"j-hYLPXiBxQe"},"source":["The data has been formatted to be entirely lowercase and not contain any emojis or non-english characters. In contrastto some methods, punctuation has been left in along with numbers."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"DXuudTC9BPui","executionInfo":{"status":"ok","timestamp":1620477416866,"user_tz":-60,"elapsed":437,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"6c99698f-0997-4670-e539-69fba5c4e6af"},"source":["askreddit = pd.read_csv('/gdrive/My Drive/Reddit_Data/AskReddit_5000.csv', index_col = 0)\n","askreddit.head()"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>raw_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>elder redditors, at the dawn of the internet w...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>redditors what was your best or worst time in ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>if your pet was in a room with 100 animals tha...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what saying needs to die?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>the world ends tomorrow, you have to choose on...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                           raw_title\n","0  elder redditors, at the dawn of the internet w...\n","1  redditors what was your best or worst time in ...\n","2  if your pet was in a room with 100 animals tha...\n","3                          what saying needs to die?\n","4  the world ends tomorrow, you have to choose on..."]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"RsHFmG18CcSF"},"source":["# Format Data"]},{"cell_type":"markdown","metadata":{"id":"RDeSCiN4ChVu"},"source":["Each individual question is a string. Here each question is appended to one long string where the character `\\n` (new line) is used to seperate them."]},{"cell_type":"code","metadata":{"id":"6bw_y4f2Ci9Y","executionInfo":{"status":"ok","timestamp":1620477417915,"user_tz":-60,"elapsed":336,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["raw_str = str()\n","for i in range(len(askreddit)):\n","  raw_str += askreddit['raw_title'].iloc[i] + '\\n'"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cg1TIv5BtE-","executionInfo":{"status":"ok","timestamp":1620477418165,"user_tz":-60,"elapsed":572,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"c745ff2d-e129-4678-b41c-b00525542d34"},"source":["print(raw_str[:200])"],"execution_count":24,"outputs":[{"output_type":"stream","text":["elder redditors, at the dawn of the internet what was popular digital slang and what did it mean?\n","redditors what was your best or worst time in a game of truth or dare?\n","if your pet was in a room with \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"RzcQK4YfDitG"},"source":["# Character and Mapping"]},{"cell_type":"markdown","metadata":{"id":"pVlimLMPDndu"},"source":["Lets see how many unique characters we have in our dataset and how many characters we have in total!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Ee8Bz2BDRIm","executionInfo":{"status":"ok","timestamp":1620477419720,"user_tz":-60,"elapsed":523,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"82e4db69-2d54-498f-c0f1-9ab0073a8519"},"source":["n_chars = len(raw_str)\n","vocab = sorted(set(raw_str))\n","print(\"Total Characters: \", n_chars)\n","print (\"Total Vocab: \", len(vocab))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Total Characters:  388532\n","Total Vocab:  62\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gt2i5fsMEDts"},"source":["For each unique character, we want to assign a unique ID. For example `{a: 1, b: 2, c: 3, ...}`."]},{"cell_type":"code","metadata":{"id":"4ZZwyNUlDtJ0","executionInfo":{"status":"ok","timestamp":1620477419924,"user_tz":-60,"elapsed":711,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["ids_from_chars = preprocessing.StringLookup(\n","    vocabulary=list(vocab))"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eeIZe3pQEZKG"},"source":["To be able to read the output from the model, we need to able to convert the unique IDs back to characters."]},{"cell_type":"code","metadata":{"id":"Ou4pdk8RDtkz","executionInfo":{"status":"ok","timestamp":1620477419925,"user_tz":-60,"elapsed":706,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ec9zNulSEtGe"},"source":["As part of converting the output back into real words we want to join the output characters back into a full string."]},{"cell_type":"code","metadata":{"id":"o--veftXEr64","executionInfo":{"status":"ok","timestamp":1620477419925,"user_tz":-60,"elapsed":697,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9h86zX7vF41X"},"source":["# Preparing Data for the Model"]},{"cell_type":"markdown","metadata":{"id":"0BTwRAtQFJqW"},"source":["We need to actually perform the conversion of our data from string to ID. "]},{"cell_type":"code","metadata":{"id":"woy0jFKQE8vR","executionInfo":{"status":"ok","timestamp":1620477421196,"user_tz":-60,"elapsed":682,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["all_ids = ids_from_chars(tf.strings.unicode_split(raw_str, 'UTF-8'))"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oddku3NlFtPu"},"source":["Convert the data into dataset format for tensorflow to train on."]},{"cell_type":"code","metadata":{"id":"otEZS4lRFXp8","executionInfo":{"status":"ok","timestamp":1620477421197,"user_tz":-60,"elapsed":674,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9n5cbKgKF-8G"},"source":["We want to define a length of a string to pass through the model as a single instance. Think of 100 characters as being the text-equivalent to an image being passed through a classifier."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYsqfTREFaIJ","executionInfo":{"status":"ok","timestamp":1620477421198,"user_tz":-60,"elapsed":665,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"2d5a6713-6820-4249-aecf-d975b666cd74"},"source":["seq_length = 100\n","examples_per_epoch = len(raw_str)//(seq_length+1)    # a//b performs a/b but removes any remainder when a/n*b != 0 and a>n*b. \n","print(examples_per_epoch)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["3846\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TewDumfdGrQ0"},"source":["`drop_remainder` prevents the smaller batch at the end with $<$64 instances from being produced to ensure batches are all the same size."]},{"cell_type":"code","metadata":{"id":"iAYOggQbGpvX","executionInfo":{"status":"ok","timestamp":1620477421199,"user_tz":-60,"elapsed":655,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)  "],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6T3eQjJPG_x9"},"source":["Split the sequences so that the target is moved one step forward.\n","\n","For example:\n","- string: 'hello'\n","- input : 'hell'\n","- target: 'ello'"]},{"cell_type":"code","metadata":{"id":"c3Mlf45zGj7r","executionInfo":{"status":"ok","timestamp":1620477421199,"user_tz":-60,"elapsed":648,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text"],"execution_count":33,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4HJxs3D0HEEN"},"source":["Map this splitting to our sequences."]},{"cell_type":"code","metadata":{"id":"S3lLj9HDHDaK","executionInfo":{"status":"ok","timestamp":1620477421200,"user_tz":-60,"elapsed":641,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["dataset = sequences.map(split_input_target)"],"execution_count":34,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jWcFt-atHLCd"},"source":["Let's  visualize and example."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0zwfGuVmHKFt","executionInfo":{"status":"ok","timestamp":1620477421200,"user_tz":-60,"elapsed":634,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"0b18d860-59a6-4c20-9fbf-52319136562a"},"source":["for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Input : b'elder redditors, at the dawn of the internet what was popular digital slang and what did it mean?\\nre'\n","Target: b'lder redditors, at the dawn of the internet what was popular digital slang and what did it mean?\\nred'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d-oU8gV4HTIG"},"source":["Put the data into batches and then into the data format required to train.\n","\n","In the cell below, the buffer is a size which TensorFlow will shuffle within."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uvS-KbhWHPPB","executionInfo":{"status":"ok","timestamp":1620477421200,"user_tz":-60,"elapsed":628,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"a1c71360-f845-45c0-db9e-0c8fefcf80d3"},"source":["BATCH_SIZE = 64\n","BUFFER_SIZE = 20000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"p2cGsgk2Htve"},"source":["# Defining the Model\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zLv2nLT6H57P"},"source":["The model maps the characters onto an embbedding, sets the number of rnn units, calls these units, updates the states and then returns these states. The output size is a fully connected (dense) layer that has the number of nodes equal to our vocab size."]},{"cell_type":"code","metadata":{"id":"kHk432U2H4aO","executionInfo":{"status":"ok","timestamp":1620477422647,"user_tz":-60,"elapsed":472,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    \n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m2lwJxR-IJ2_"},"source":["You need to specify the voca size (number of unique characters) as this will be the number of nodes in the final layer. \n","\n","The embedding dimension and number of RNN units can be changed to affect the model."]},{"cell_type":"code","metadata":{"id":"XqQ3u7yYHsEw","executionInfo":{"status":"ok","timestamp":1620477422648,"user_tz":-60,"elapsed":468,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Am_9UK0IIlss"},"source":["Create the model object."]},{"cell_type":"code","metadata":{"id":"7G4v-JqdIkiO","executionInfo":{"status":"ok","timestamp":1620477422650,"user_tz":-60,"elapsed":467,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["model = MyModel(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jGme_B_KIwFG"},"source":["Let's pass one batch through the model to:\n","- see if the model accepts and input and produces and output successfully,\n","- visualise if the output is sheer nonesense."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--r3TqNiIgRl","executionInfo":{"status":"ok","timestamp":1620477454784,"user_tz":-60,"elapsed":32594,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"c445aa11-b5b2-446e-d14e-c40212772844"},"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["(64, 100, 64) # (batch_size, sequence_length, vocab_size)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VbUdqLSjI_7E","executionInfo":{"status":"ok","timestamp":1620477454785,"user_tz":-60,"elapsed":32586,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"3319e920-d53f-4f0e-9663-c53760d82852"},"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n","\n","print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Input:\n"," b'you read?\\nwhat do you guys think of the recent way in which instagram users are \"turning $150 into $'\n","\n","Next Char Predictions:\n"," b'+pq]++ar5~[UNK]3$ps_$-.u|u64h/bf6xr[UNK]2\\n/g*~y]j?|&e3r+](b-#6jn19%]m_![og9/wig=p4y[UNK]o63*-i&k\\'a]*w~(-\"-ow4r-'\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BBLqRqGxJGEl"},"source":["Looks like nonesense to me!"]},{"cell_type":"markdown","metadata":{"id":"Qpm9Ao8PJKMW"},"source":["Define a loss function."]},{"cell_type":"code","metadata":{"id":"IbD-a7fiJDUE","executionInfo":{"status":"ok","timestamp":1620477454786,"user_tz":-60,"elapsed":32585,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GAJ4CYdaJUpc"},"source":["Looking at the loss between our example input and output batch, the exponential of the mean loss should roughly equal the number of characters as most characters are predicted wrong."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKvghsirJT0u","executionInfo":{"status":"ok","timestamp":1620477454787,"user_tz":-60,"elapsed":32579,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"7864c550-07d1-40e9-cee9-cce661edcf8b"},"source":["example_batch_loss = loss(target_example_batch, example_batch_predictions)\n","mean_loss = example_batch_loss.numpy().mean()\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", mean_loss)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Prediction shape:  (64, 100, 64)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         4.15827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1fr7tQUJRwT","executionInfo":{"status":"ok","timestamp":1620477454787,"user_tz":-60,"elapsed":32570,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"952489c1-f7b6-473e-b5ed-ff380683115c"},"source":["print(f'Num characters: {len(vocab)}')\n","print(f'Exp of Loss   : {tf.exp(mean_loss).numpy():.5f}')"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Num characters: 62\n","Exp of Loss   : 63.96077\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"anqdVt_0J-f-"},"source":["Compile the model with the optimizer 'adam' and our loss function."]},{"cell_type":"code","metadata":{"id":"5y0vdtT1JmyU","executionInfo":{"status":"ok","timestamp":1620477454788,"user_tz":-60,"elapsed":32569,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["model.compile(optimizer='adam', loss=loss)"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XdmsM76dKIjP"},"source":["Define some checkpoints to save the model at."]},{"cell_type":"code","metadata":{"id":"f7B8_K0yKHbV","executionInfo":{"status":"ok","timestamp":1620477454788,"user_tz":-60,"elapsed":32566,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["checkpoint_dir = './training_checkpoints'                         ## The directory where the chepoints will be saved.\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")  ## The name of the file at such a checkpoint.\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FuE0ORWBLdJW"},"source":["# Run the Model"]},{"cell_type":"markdown","metadata":{"id":"V1NibQguKckh"},"source":["Define a number of epochs."]},{"cell_type":"code","metadata":{"id":"YuISTt6wKZo-","executionInfo":{"status":"ok","timestamp":1620477463229,"user_tz":-60,"elapsed":497,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["Epochs = 100"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YclbqfybKhIL"},"source":["Run it!\n","\n","(*Model should take roughly 10 minutes to train for 100 epochs on Colabs free GPU*)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZlpOSsSkKh9_","executionInfo":{"status":"ok","timestamp":1620477860770,"user_tz":-60,"elapsed":394165,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"ad9b0f6c-adad-4418-b69c-c366a945ca1c"},"source":["history = model.fit(dataset, epochs=Epochs, callbacks=[checkpoint_callback])"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","60/60 [==============================] - 5s 55ms/step - loss: 3.7512\n","Epoch 2/100\n","60/60 [==============================] - 4s 54ms/step - loss: 2.3840\n","Epoch 3/100\n","60/60 [==============================] - 4s 54ms/step - loss: 2.1532\n","Epoch 4/100\n","60/60 [==============================] - 4s 55ms/step - loss: 1.9571\n","Epoch 5/100\n","60/60 [==============================] - 4s 55ms/step - loss: 1.8020\n","Epoch 6/100\n","60/60 [==============================] - 4s 55ms/step - loss: 1.6679\n","Epoch 7/100\n","60/60 [==============================] - 4s 56ms/step - loss: 1.5712\n","Epoch 8/100\n","60/60 [==============================] - 4s 56ms/step - loss: 1.4653\n","Epoch 9/100\n","60/60 [==============================] - 4s 56ms/step - loss: 1.3876\n","Epoch 10/100\n","60/60 [==============================] - 4s 56ms/step - loss: 1.3163\n","Epoch 11/100\n","60/60 [==============================] - 4s 57ms/step - loss: 1.2483\n","Epoch 12/100\n","60/60 [==============================] - 4s 57ms/step - loss: 1.1964\n","Epoch 13/100\n","60/60 [==============================] - 4s 57ms/step - loss: 1.1366\n","Epoch 14/100\n","60/60 [==============================] - 4s 57ms/step - loss: 1.0795\n","Epoch 15/100\n","60/60 [==============================] - 4s 58ms/step - loss: 1.0244\n","Epoch 16/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.9649\n","Epoch 17/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.9060\n","Epoch 18/100\n","60/60 [==============================] - 4s 59ms/step - loss: 0.8425\n","Epoch 19/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.7801\n","Epoch 20/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.7169\n","Epoch 21/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.6492\n","Epoch 22/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.5854\n","Epoch 23/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.5264\n","Epoch 24/100\n","60/60 [==============================] - 4s 56ms/step - loss: 0.4679\n","Epoch 25/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.4143\n","Epoch 26/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.3669\n","Epoch 27/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.3263\n","Epoch 28/100\n","60/60 [==============================] - 4s 56ms/step - loss: 0.2896\n","Epoch 29/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.2622\n","Epoch 30/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.2367\n","Epoch 31/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.2165\n","Epoch 32/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1986\n","Epoch 33/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1832\n","Epoch 34/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1684\n","Epoch 35/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1617\n","Epoch 36/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1513\n","Epoch 37/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1462\n","Epoch 38/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1392\n","Epoch 39/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1333\n","Epoch 40/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1316\n","Epoch 41/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1269\n","Epoch 42/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1245\n","Epoch 43/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1216\n","Epoch 44/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1200\n","Epoch 45/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1215\n","Epoch 46/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1198\n","Epoch 47/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1215\n","Epoch 48/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1237\n","Epoch 49/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1240\n","Epoch 50/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1231\n","Epoch 51/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1251\n","Epoch 52/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1307\n","Epoch 53/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1367\n","Epoch 54/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1426\n","Epoch 55/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1435\n","Epoch 56/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1404\n","Epoch 57/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1375\n","Epoch 58/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1291\n","Epoch 59/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1245\n","Epoch 60/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1111\n","Epoch 61/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.1025\n","Epoch 62/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0946\n","Epoch 63/100\n","60/60 [==============================] - 4s 57ms/step - loss: 0.0883\n","Epoch 64/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0829\n","Epoch 65/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0800\n","Epoch 66/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0769\n","Epoch 67/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0757\n","Epoch 68/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0734\n","Epoch 69/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0733\n","Epoch 70/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0723\n","Epoch 71/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0715\n","Epoch 72/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0705\n","Epoch 73/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0708\n","Epoch 74/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0706\n","Epoch 75/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0705\n","Epoch 76/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0702\n","Epoch 77/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0704\n","Epoch 78/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0708\n","Epoch 79/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0708\n","Epoch 80/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0715\n","Epoch 81/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0720\n","Epoch 82/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0740\n","Epoch 83/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0826\n","Epoch 84/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.2058\n","Epoch 85/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.7896\n","Epoch 86/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.6580\n","Epoch 87/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.4641\n","Epoch 88/100\n","60/60 [==============================] - 4s 59ms/step - loss: 0.3402\n","Epoch 89/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.2607\n","Epoch 90/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.2024\n","Epoch 91/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1640\n","Epoch 92/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1348\n","Epoch 93/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.1117\n","Epoch 94/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0976\n","Epoch 95/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0857\n","Epoch 96/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0783\n","Epoch 97/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0727\n","Epoch 98/100\n","60/60 [==============================] - 4s 59ms/step - loss: 0.0695\n","Epoch 99/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0674\n","Epoch 100/100\n","60/60 [==============================] - 4s 58ms/step - loss: 0.0663\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C5CUVY-fKo5u"},"source":["Let's see how the model trained over the epochs to give us an idea of what we can expect. If the loss is still decreasing then we need to train it for longer and if has plataeued for 50 epochs then the model will likely have overfitted. Overfitting will cause the model to output questions that were within our training set."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"oRlX0kbrKise","executionInfo":{"status":"ok","timestamp":1620478020608,"user_tz":-60,"elapsed":636,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"502c1d3c-9072-401d-8e8a-cae37e12e993"},"source":["plt.figure(figsize = (6,6))\n","plt.plot(range(len(history.history['loss'])), history.history['loss'])\n","plt.show()  "],"execution_count":50,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x432 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"RS9qQo5BLKdG"},"source":["# Model Output"]},{"cell_type":"markdown","metadata":{"id":"NqjyAt8xPN7u"},"source":["The following function will generate outputs from the model using the character mapping specified earlier."]},{"cell_type":"code","metadata":{"id":"DJ7i1KLZPFQX","executionInfo":{"status":"ok","timestamp":1620478023676,"user_tz":-60,"elapsed":721,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"\" or \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['', '[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"\" or \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HtM3DtlTPaUG"},"source":["Pass the model and our character mappings into the class object."]},{"cell_type":"code","metadata":{"id":"Bal5XqgGPhNC","executionInfo":{"status":"ok","timestamp":1620478026137,"user_tz":-60,"elapsed":502,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8DSufkJPmdk"},"source":["Lets produce some questions!"]},{"cell_type":"markdown","metadata":{"id":"_on6ArefPpSl"},"source":["All we are doing is specifying a start set of characters (can be one letter, one word etc.), producing the next character and updating the state of the RNN. The new character and states are then passed into the RNN and so on until stopped."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I06nt9JKPjwH","executionInfo":{"status":"ok","timestamp":1620478038132,"user_tz":-60,"elapsed":1186,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"3109c938-3d0f-4360-b3e5-980e36ba32ed"},"source":["start = time.time()\n","states = None\n","next_char = tf.constant([\"what\"])\n","result = [next_char]\n","\n","for n in range(300): ##   Specify the number of characters to produce.\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","\n","result_string = result[0].numpy().decode('utf-8')\n","\n","print(result_string, '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["what's the dumbest advice you've got from a relative?\n","i lost a dear friend today. what are some things that are better to be stupid about?\n","[serious] people who have multiple reddit accounts - why?\n","what is screwed up about the world but made you force your so or house in your neigned?\n","how do you justify  \n","\n","________________________________________________________________________________\n","\n","Run time: 0.6240875720977783\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NpIr6emDQEt0"},"source":["Those are some pretty real looking words! This AI has learnt how to spell words from scratch! However, some of the questions don't made great deal of sense.\n","\n","Some of these questions look a bit too-well put-together so we will use the leu score to compare our specified question with all of our input questions and display the closest matching question."]},{"cell_type":"markdown","metadata":{"id":"20oY29a9QsFV"},"source":["Each of the output strings are actually one big string but the print statement doesn't dsiplay the `\\n` so they appear to be seperate. Lets seperate out the output questions."]},{"cell_type":"code","metadata":{"id":"hOnyq2NwQC1O","executionInfo":{"status":"ok","timestamp":1620478042056,"user_tz":-60,"elapsed":629,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["result_string = result_string.split('\\n')"],"execution_count":55,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VnNMjL09Q7Kk"},"source":["Specify the output line you want to test (indexing from 0)."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZTkD6vlqQ5XV","executionInfo":{"status":"ok","timestamp":1620478043606,"user_tz":-60,"elapsed":508,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"9e2463f9-707d-4d17-cbeb-c6ed694e222d"},"source":["test_result = result_string[0]\n","print(test_result)"],"execution_count":56,"outputs":[{"output_type":"stream","text":["what's the dumbest advice you've got from a relative?\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3EhL-VY1RCz1"},"source":["Let's compare!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XnTfmvMRB-V","executionInfo":{"status":"ok","timestamp":1620478159350,"user_tz":-60,"elapsed":1095,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"4488e7f1-a9c5-41c8-9a2d-2b4e455c3509"},"source":["raw_titles = [title.split() for title in askreddit['raw_title']]\n","bleus = [sentence_bleu([raw_titles[i]], test_result.split()) for i in range(len(raw_titles))]\n","max_id = bleus.index(max(bleus))\n","\n","print('_'*50)\n","print('\\n\\n')\n","print('Model Output  : {}'.format(test_result))\n","print('Closest Title : {}'.format(askreddit['raw_title'].iloc[max_id]))\n","print('\\n\\n')\n","print('_'*50)"],"execution_count":64,"outputs":[{"output_type":"stream","text":["__________________________________________________\n","\n","\n","\n","Model Output  : what's the dumbest advice you've got from a relative?\n","Closest Title : what's the dumbest advice you've got from a relative?\n","\n","\n","\n","__________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rJdcLed7RUO1"},"source":["In this case, the model has overfitted and produced a question that already exists withing the training dataset. This is generally the case for the first line generated.\n","\n","Try seeding the model with different words or even phrases like 'how'."]},{"cell_type":"markdown","metadata":{"id":"alv6ENGf9x43"},"source":["Some questions also appear to make too much sense but don't match up with existing questions. It's worth searching some key words within the dataset to see if any questions exist that are slight modifications of our output."]},{"cell_type":"code","metadata":{"id":"tMGW5sQN9u_8","executionInfo":{"status":"ok","timestamp":1620478161690,"user_tz":-60,"elapsed":454,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}}},"source":["def search_word(df, word):\n","  for i in range(len(df)):\n","    if word in df['raw_title'].iloc[i]:\n","      print(df['raw_title'].iloc[i])"],"execution_count":65,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LXHNmcCA-hOZ","executionInfo":{"status":"ok","timestamp":1620478179019,"user_tz":-60,"elapsed":629,"user":{"displayName":"Joe Sims","photoUrl":"","userId":"18236573323563343442"}},"outputId":"8b965116-7614-434e-90e0-3188987c514e"},"source":["search_word(askreddit, 'dummest')"],"execution_count":67,"outputs":[{"output_type":"stream","text":["what is the dummest thing you did on reddit?\n"],"name":"stdout"}]}]}